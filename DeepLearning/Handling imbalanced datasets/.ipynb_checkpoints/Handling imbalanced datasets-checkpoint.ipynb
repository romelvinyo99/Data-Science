{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "be6214c5-c6e5-4341-832a-b1ab03549fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "df = pd.read_csv(\"customer_churn.csv\")\n",
    "df.drop(columns = [\"customerID\"], axis = 1, inplace = True)\n",
    "# Ensure that TotalCharges is converted correctly\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "# Drop any rows with missing TotalCharges values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8e3f3a79-fc11-4047-b1aa-10bf28f2a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numeric\n",
    "yes_no_column = [\"gender\", \"Partner\", \"Dependents\", \"PhoneService\", \"MultipleLines\", \"OnlineSecurity\",\n",
    "                 \"OnlineBackup\", \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\",\n",
    "                 \"PaperlessBilling\", \"Churn\"]\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in yes_no_column:\n",
    "    df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d869cf93-645f-4c43-af0a-e0f2f608ab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with more than two categories\n",
    "df = pd.get_dummies(df, columns=[\"InternetService\", \"Contract\", \"PaymentMethod\"])\n",
    "\n",
    "# Scale numeric columns\n",
    "cols_to_scale = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "scaler = MinMaxScaler()\n",
    "df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4d9eb99d-c91a-41b0-b895-399ce41b3e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Ensure all data is float32\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "68c704df-b01c-4881-a5fd-a5c105ecbd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    # Build and compile the model\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(26, input_dim=26, activation=\"relu\"),\n",
    "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs = 100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs = 100, class_weights = weights)\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    print(\"Classification report\\n\", classification_report(y_test, y_preds))\n",
    "    return y_preds    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f62d985-8829-4d1f-a921-f41d40e670e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "176/176 [==============================] - 1s 1ms/step - loss: 0.4651 - accuracy: 0.7756\n",
      "Epoch 2/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7996\n",
      "Epoch 3/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.7995\n",
      "Epoch 4/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8046\n",
      "Epoch 5/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4161 - accuracy: 0.8064\n",
      "Epoch 6/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.8069\n",
      "Epoch 7/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4118 - accuracy: 0.8053\n",
      "Epoch 8/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8107\n",
      "Epoch 9/100\n",
      "176/176 [==============================] - 0s 988us/step - loss: 0.4095 - accuracy: 0.8103\n",
      "Epoch 10/100\n",
      "176/176 [==============================] - 0s 975us/step - loss: 0.4081 - accuracy: 0.8133\n",
      "Epoch 11/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4073 - accuracy: 0.8116\n",
      "Epoch 12/100\n",
      "176/176 [==============================] - 0s 989us/step - loss: 0.4067 - accuracy: 0.8100\n",
      "Epoch 13/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8158\n",
      "Epoch 14/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8121\n",
      "Epoch 15/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4024 - accuracy: 0.8142\n",
      "Epoch 16/100\n",
      "176/176 [==============================] - 0s 977us/step - loss: 0.4022 - accuracy: 0.8162\n",
      "Epoch 17/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4015 - accuracy: 0.8126\n",
      "Epoch 18/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3999 - accuracy: 0.8153\n",
      "Epoch 19/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.4002 - accuracy: 0.8183\n",
      "Epoch 20/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8144\n",
      "Epoch 21/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3984 - accuracy: 0.8146\n",
      "Epoch 22/100\n",
      "176/176 [==============================] - 0s 992us/step - loss: 0.3974 - accuracy: 0.8160\n",
      "Epoch 23/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3970 - accuracy: 0.8180\n",
      "Epoch 24/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3961 - accuracy: 0.8167\n",
      "Epoch 25/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8169\n",
      "Epoch 26/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3953 - accuracy: 0.8165\n",
      "Epoch 27/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3939 - accuracy: 0.8180\n",
      "Epoch 28/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3944 - accuracy: 0.8192\n",
      "Epoch 29/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3934 - accuracy: 0.8160\n",
      "Epoch 30/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3924 - accuracy: 0.8151\n",
      "Epoch 31/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3922 - accuracy: 0.8194\n",
      "Epoch 32/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3917 - accuracy: 0.8178\n",
      "Epoch 33/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3912 - accuracy: 0.8160\n",
      "Epoch 34/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3906 - accuracy: 0.8160\n",
      "Epoch 35/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3903 - accuracy: 0.8194\n",
      "Epoch 36/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3902 - accuracy: 0.8190\n",
      "Epoch 37/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8178\n",
      "Epoch 38/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8188\n",
      "Epoch 39/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3884 - accuracy: 0.8176\n",
      "Epoch 40/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3882 - accuracy: 0.8188\n",
      "Epoch 41/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3886 - accuracy: 0.8197\n",
      "Epoch 42/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3868 - accuracy: 0.8187\n",
      "Epoch 43/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3875 - accuracy: 0.8171\n",
      "Epoch 44/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3867 - accuracy: 0.8201\n",
      "Epoch 45/100\n",
      "176/176 [==============================] - 0s 997us/step - loss: 0.3865 - accuracy: 0.8197\n",
      "Epoch 46/100\n",
      "176/176 [==============================] - 0s 993us/step - loss: 0.3859 - accuracy: 0.8212\n",
      "Epoch 47/100\n",
      "176/176 [==============================] - 0s 998us/step - loss: 0.3857 - accuracy: 0.8201\n",
      "Epoch 48/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 0.8203\n",
      "Epoch 49/100\n",
      "176/176 [==============================] - 0s 986us/step - loss: 0.3856 - accuracy: 0.8188\n",
      "Epoch 50/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.8196\n",
      "Epoch 51/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3841 - accuracy: 0.8224\n",
      "Epoch 52/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3838 - accuracy: 0.8208\n",
      "Epoch 53/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3834 - accuracy: 0.8228\n",
      "Epoch 54/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3835 - accuracy: 0.8199\n",
      "Epoch 55/100\n",
      "176/176 [==============================] - 0s 996us/step - loss: 0.3830 - accuracy: 0.8201\n",
      "Epoch 56/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8204\n",
      "Epoch 57/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3824 - accuracy: 0.8228\n",
      "Epoch 58/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3818 - accuracy: 0.8229\n",
      "Epoch 59/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3831 - accuracy: 0.8208\n",
      "Epoch 60/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3825 - accuracy: 0.8206\n",
      "Epoch 61/100\n",
      "176/176 [==============================] - 0s 988us/step - loss: 0.3811 - accuracy: 0.8213\n",
      "Epoch 62/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8222\n",
      "Epoch 63/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3801 - accuracy: 0.8224\n",
      "Epoch 64/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8231\n",
      "Epoch 65/100\n",
      "176/176 [==============================] - 0s 984us/step - loss: 0.3800 - accuracy: 0.8229\n",
      "Epoch 66/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3792 - accuracy: 0.8224\n",
      "Epoch 67/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3806 - accuracy: 0.8213\n",
      "Epoch 68/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3802 - accuracy: 0.8242\n",
      "Epoch 69/100\n",
      "176/176 [==============================] - 0s 1000us/step - loss: 0.3792 - accuracy: 0.8231\n",
      "Epoch 70/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3796 - accuracy: 0.8222\n",
      "Epoch 71/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3789 - accuracy: 0.8252\n",
      "Epoch 72/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3795 - accuracy: 0.8204\n",
      "Epoch 73/100\n",
      "176/176 [==============================] - 0s 994us/step - loss: 0.3786 - accuracy: 0.8229\n",
      "Epoch 74/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8226\n",
      "Epoch 75/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8222\n",
      "Epoch 76/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8224\n",
      "Epoch 77/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3776 - accuracy: 0.8231\n",
      "Epoch 78/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3771 - accuracy: 0.8229\n",
      "Epoch 79/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3775 - accuracy: 0.8220\n",
      "Epoch 80/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3786 - accuracy: 0.8208\n",
      "Epoch 81/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3783 - accuracy: 0.8217\n",
      "Epoch 82/100\n",
      "176/176 [==============================] - 0s 992us/step - loss: 0.3770 - accuracy: 0.8240\n",
      "Epoch 83/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8242\n",
      "Epoch 84/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8245\n",
      "Epoch 85/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3767 - accuracy: 0.8247\n",
      "Epoch 86/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8229\n",
      "Epoch 87/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8231\n",
      "Epoch 88/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3762 - accuracy: 0.8215\n",
      "Epoch 89/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3759 - accuracy: 0.8244\n",
      "Epoch 90/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3757 - accuracy: 0.8201\n",
      "Epoch 91/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3753 - accuracy: 0.8244\n",
      "Epoch 92/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3756 - accuracy: 0.8247\n",
      "Epoch 93/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8254\n",
      "Epoch 94/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3744 - accuracy: 0.8220\n",
      "Epoch 95/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8229\n",
      "Epoch 96/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3750 - accuracy: 0.8220\n",
      "Epoch 97/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8252\n",
      "Epoch 98/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3734 - accuracy: 0.8236\n",
      "Epoch 99/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3736 - accuracy: 0.8249\n",
      "Epoch 100/100\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.3740 - accuracy: 0.8235\n",
      "44/44 [==============================] - 0s 991us/step - loss: 0.4613 - accuracy: 0.7783\n",
      "[0.4613082706928253, 0.778251588344574]\n",
      "44/44 [==============================] - 0s 752us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.88      0.85      1033\n",
      "         1.0       0.60      0.51      0.55       374\n",
      "\n",
      "    accuracy                           0.78      1407\n",
      "   macro avg       0.71      0.69      0.70      1407\n",
      "weighted avg       0.77      0.78      0.77      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4ab10274-9adc-4bd3-a666-b745a502d1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0.0    1033\n",
       "1.0     374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for imbalance\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d850de9-81e5-426d-889f-77a9ba2ada4e",
   "metadata": {},
   "source": [
    "Under-sampling techinique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb0489eb-4418-48ce-b5ed-b464736377af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class count\n",
    "count_class_0, count_class_1 = df[\"Churn\"].value_counts()\n",
    "\n",
    "# divide by class\n",
    "\n",
    "df_class_0 = df[df[\"Churn\"] == 0 ]\n",
    "df_class_1 = df[df[\"Churn\"] == 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "585c0a36-f3ba-4932-8a0f-c7bae3f2af0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5163, 1869)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the counts for each class\n",
    "count_class_0, count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6103fed5-610f-459c-9f71-5151e4f9a2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5163, 27), (1869, 27))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the imbalance\n",
    "df_class_0.shape , df_class_1.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6378a127-54ff-462b-b44d-ec83dcc0be45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    1869\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# undersampling the majority class\n",
    "\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "\n",
    "# combining the two classes now(sample) - and creating a new balanced dataset\n",
    "\n",
    "undersample_df = pd.concat([df_class_0_under, df_class_1], axis = 0)\n",
    "undersample_df[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "459d9c20-6388-4721-96ac-54a6d976bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2990, 26)\n",
      "y_train shape: (2990,)\n",
      "X_test shape: (748, 26)\n",
      "y_test shape: (748,)\n",
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 1ms/step - loss: 0.6064 - accuracy: 0.6659\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7448\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7559\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7592\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7602\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7609\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7642\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7615\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7629\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7652\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 992us/step - loss: 0.4782 - accuracy: 0.7699\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4765 - accuracy: 0.7686\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7692\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4733 - accuracy: 0.7706\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7732\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7726\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.7739\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7739\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 1000us/step - loss: 0.4678 - accuracy: 0.7716\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 995us/step - loss: 0.4671 - accuracy: 0.7746\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4671 - accuracy: 0.7696\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 993us/step - loss: 0.4637 - accuracy: 0.7726\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7742\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7776\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7709\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 999us/step - loss: 0.4619 - accuracy: 0.7773\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4611 - accuracy: 0.7776\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7766\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7753\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7776\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7783\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7786\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7796\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4579 - accuracy: 0.7796\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7763\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7779\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7769\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 968us/step - loss: 0.4561 - accuracy: 0.7759\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4545 - accuracy: 0.7833\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7799\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7806\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7803\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.7823\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7799\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7793\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 998us/step - loss: 0.4496 - accuracy: 0.7816\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4513 - accuracy: 0.7796\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4509 - accuracy: 0.7813\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4507 - accuracy: 0.7789\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7829\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7826\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7806\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7860\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 999us/step - loss: 0.4470 - accuracy: 0.7813\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4469 - accuracy: 0.7826\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4464 - accuracy: 0.7819\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4462 - accuracy: 0.7839\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4455 - accuracy: 0.7839\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4460 - accuracy: 0.7839\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7819\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7856\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4440 - accuracy: 0.7829\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.7843\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7863\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.7906\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7880\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4431 - accuracy: 0.7873\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4428 - accuracy: 0.7880\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4418 - accuracy: 0.7886\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4419 - accuracy: 0.7839\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7823\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7860\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7876\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7893\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4410 - accuracy: 0.7839\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4391 - accuracy: 0.7860\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7866\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7863\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 992us/step - loss: 0.4382 - accuracy: 0.7853\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4384 - accuracy: 0.7880\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7856\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7900\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7880\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4372 - accuracy: 0.7913\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4376 - accuracy: 0.7930\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 984us/step - loss: 0.4371 - accuracy: 0.7883\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4368 - accuracy: 0.7896\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7896\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4357 - accuracy: 0.7926\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7910\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4359 - accuracy: 0.7886\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.7900\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4356 - accuracy: 0.7873\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7913\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7930\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4351 - accuracy: 0.7916\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4339 - accuracy: 0.7946\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.7913\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7873\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4341 - accuracy: 0.7916\n",
      "24/24 [==============================] - 0s 943us/step - loss: 0.5253 - accuracy: 0.7433\n",
      "[0.5253141522407532, 0.7433155179023743]\n",
      "24/24 [==============================] - 0s 827us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.75       374\n",
      "         1.0       0.75      0.72      0.74       374\n",
      "\n",
      "    accuracy                           0.74       748\n",
      "   macro avg       0.74      0.74      0.74       748\n",
      "weighted avg       0.74      0.74      0.74       748\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure you are creating your train-test splits using the right DataFrame\n",
    "X = undersample_df.drop(columns=[\"Churn\"], axis=1)\n",
    "y = undersample_df[\"Churn\"]\n",
    "\n",
    "# Stratify to maintain balance in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "# Ensure you convert your datasets to the correct data types\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32) # Correct the conversion of y_train\n",
    "X_test = X_test.astype(np.float32)   # Use X_test instead of X_train\n",
    "y_test = y_test.astype(np.float32)   # Use y_test instead of X_train\n",
    "\n",
    "# Check the shape after the split to ensure correctness\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Call the ANN function\n",
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938210fb-2295-4ed4-81b2-0b625db6cb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "From the above you will see the precision and recall has improved compared to the initial\n",
    "Due to this the f1 score improved compared to imbalanced dataset\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c6007bd-eb7a-4c17-9206-8bed61281aac",
   "metadata": {},
   "source": [
    "Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f47233f-3240-41f0-9a06-75356812a512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5163, 1869)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_class_0, count_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6341a6c9-81e4-42b9-90fb-03714e7f28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_1_over = df_class_1.sample(count_class_0, replace = True) \n",
    "\n",
    "oversample_df = pd.concat([df_class_1_over, df_class_0], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffac4312-e1dd-428a-ae08-949ac0e9ae88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8260, 26)\n",
      "y_train shape: (8260,)\n",
      "X_test shape: (2066, 26)\n",
      "y_test shape: (2066,)\n",
      "Epoch 1/100\n",
      "259/259 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7335\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4947 - accuracy: 0.7587\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4866 - accuracy: 0.7614\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 0s 1000us/step - loss: 0.4817 - accuracy: 0.7682\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4784 - accuracy: 0.7688\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 0s 1000us/step - loss: 0.4761 - accuracy: 0.7714\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 0s 990us/step - loss: 0.4734 - accuracy: 0.7732\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7745\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 0s 999us/step - loss: 0.4691 - accuracy: 0.7752\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 0s 993us/step - loss: 0.4669 - accuracy: 0.7775\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 0s 995us/step - loss: 0.4656 - accuracy: 0.7785\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 0s 990us/step - loss: 0.4631 - accuracy: 0.7788\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7809\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4605 - accuracy: 0.7821\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7798\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4570 - accuracy: 0.7829\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4555 - accuracy: 0.7839\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7843\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 0s 996us/step - loss: 0.4532 - accuracy: 0.7849\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 0s 998us/step - loss: 0.4509 - accuracy: 0.7862\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4503 - accuracy: 0.7889\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7875\n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4478 - accuracy: 0.7897\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 0s 996us/step - loss: 0.4461 - accuracy: 0.7892\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4459 - accuracy: 0.7897\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 0s 993us/step - loss: 0.4442 - accuracy: 0.7914\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 0s 995us/step - loss: 0.4443 - accuracy: 0.7898\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 0s 997us/step - loss: 0.4433 - accuracy: 0.7915\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 0s 989us/step - loss: 0.4419 - accuracy: 0.7903\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7889\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4411 - accuracy: 0.7946\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4407 - accuracy: 0.7918\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4395 - accuracy: 0.7943\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4389 - accuracy: 0.7927\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4377 - accuracy: 0.7935\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 0s 982us/step - loss: 0.4379 - accuracy: 0.7925\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4373 - accuracy: 0.7932\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4369 - accuracy: 0.7929\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7943\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 0s 986us/step - loss: 0.4357 - accuracy: 0.7975\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7939\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4334 - accuracy: 0.7952\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4340 - accuracy: 0.7936\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7947\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4319 - accuracy: 0.7956\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4323 - accuracy: 0.7959\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4318 - accuracy: 0.7989\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7956\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7954\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4299 - accuracy: 0.7989\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4304 - accuracy: 0.7965\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.8005\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4301 - accuracy: 0.7996\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 0s 995us/step - loss: 0.4276 - accuracy: 0.7992\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8024\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4272 - accuracy: 0.8011\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.8025\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4264 - accuracy: 0.8017\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4256 - accuracy: 0.7999\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 0s 999us/step - loss: 0.4263 - accuracy: 0.8010\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4257 - accuracy: 0.8038\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4249 - accuracy: 0.8029\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 0s 999us/step - loss: 0.4241 - accuracy: 0.8028\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8040\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8033\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4236 - accuracy: 0.8044\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4222 - accuracy: 0.8050\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8045\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 0s 996us/step - loss: 0.4212 - accuracy: 0.8046\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4214 - accuracy: 0.8017\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4216 - accuracy: 0.8062\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4212 - accuracy: 0.8074\n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4204 - accuracy: 0.8036\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4213 - accuracy: 0.8028\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 0s 989us/step - loss: 0.4201 - accuracy: 0.8065\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8065\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4191 - accuracy: 0.8059\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4192 - accuracy: 0.8053\n",
      "Epoch 79/100\n",
      "259/259 [==============================] - 0s 983us/step - loss: 0.4191 - accuracy: 0.8081\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4185 - accuracy: 0.8069\n",
      "Epoch 81/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4175 - accuracy: 0.8059\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4173 - accuracy: 0.8084\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8079\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4165 - accuracy: 0.8051\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4171 - accuracy: 0.8075\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 0s 990us/step - loss: 0.4162 - accuracy: 0.8097\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4157 - accuracy: 0.8084\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4163 - accuracy: 0.8077\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8070\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4147 - accuracy: 0.8075\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4152 - accuracy: 0.8090\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4141 - accuracy: 0.8105\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4139 - accuracy: 0.8084\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4135 - accuracy: 0.8115\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4144 - accuracy: 0.8067\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8099\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8093\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4133 - accuracy: 0.8102\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4126 - accuracy: 0.8051\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4114 - accuracy: 0.8093\n",
      "65/65 [==============================] - 0s 925us/step - loss: 0.4731 - accuracy: 0.7682\n",
      "[0.47312313318252563, 0.768151044845581]\n",
      "65/65 [==============================] - 0s 764us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.71      0.75      1033\n",
      "         1.0       0.74      0.83      0.78      1033\n",
      "\n",
      "    accuracy                           0.77      2066\n",
      "   macro avg       0.77      0.77      0.77      2066\n",
      "weighted avg       0.77      0.77      0.77      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure you are creating your train-test splits using the right DataFrame\n",
    "X = oversample_df.drop(columns=[\"Churn\"], axis=1)\n",
    "y = oversample_df[\"Churn\"]\n",
    "\n",
    "# Stratify to maintain balance in training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "# Ensure you convert your datasets to the correct data types\n",
    "X_train = X_train.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32) # Correct the conversion of y_train\n",
    "X_test = X_test.astype(np.float32)   # Use X_test instead of X_train\n",
    "y_test = y_test.astype(np.float32)   # Use y_test instead of X_train\n",
    "\n",
    "# Check the shape after the split to ensure correctness\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# Call the ANN function\n",
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "97142a75-239c-4a3f-95b6-951fe764193f",
   "metadata": {},
   "source": [
    "smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cf4ca384-f4eb-40b5-9c4e-7bc9d068ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = [\"Churn\"], axis = 1)\n",
    "y = df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "74cfa072-2888-4eeb-aee3-314e1c6f0f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    5163\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a2f6223f-a5e8-4070-94b0-9629e8b2d8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    5163\n",
       "1    5163\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy = \"minority\")\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "765f0840-d821-4445-a549-7794b69b231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "259/259 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7218\n",
      "Epoch 2/100\n",
      "259/259 [==============================] - 0s 998us/step - loss: 0.4600 - accuracy: 0.7822\n",
      "Epoch 3/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4480 - accuracy: 0.7881\n",
      "Epoch 4/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4398 - accuracy: 0.7932\n",
      "Epoch 5/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4328 - accuracy: 0.7971\n",
      "Epoch 6/100\n",
      "259/259 [==============================] - 0s 991us/step - loss: 0.4275 - accuracy: 0.8004\n",
      "Epoch 7/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8034\n",
      "Epoch 8/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4176 - accuracy: 0.8069\n",
      "Epoch 9/100\n",
      "259/259 [==============================] - 0s 997us/step - loss: 0.4138 - accuracy: 0.8082\n",
      "Epoch 10/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8131\n",
      "Epoch 11/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4070 - accuracy: 0.8111\n",
      "Epoch 12/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4032 - accuracy: 0.8133\n",
      "Epoch 13/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.4006 - accuracy: 0.8168\n",
      "Epoch 14/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3988 - accuracy: 0.8159\n",
      "Epoch 15/100\n",
      "259/259 [==============================] - 0s 995us/step - loss: 0.3962 - accuracy: 0.8177\n",
      "Epoch 16/100\n",
      "259/259 [==============================] - 0s 1000us/step - loss: 0.3943 - accuracy: 0.8183\n",
      "Epoch 17/100\n",
      "259/259 [==============================] - 0s 993us/step - loss: 0.3930 - accuracy: 0.8192\n",
      "Epoch 18/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8200\n",
      "Epoch 19/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3896 - accuracy: 0.8217\n",
      "Epoch 20/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3878 - accuracy: 0.8213\n",
      "Epoch 21/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8222\n",
      "Epoch 22/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3842 - accuracy: 0.8254\n",
      "Epoch 23/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3833 - accuracy: 0.8266\n",
      "Epoch 24/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3823 - accuracy: 0.8288\n",
      "Epoch 25/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3807 - accuracy: 0.8285\n",
      "Epoch 26/100\n",
      "259/259 [==============================] - 0s 997us/step - loss: 0.3812 - accuracy: 0.8249\n",
      "Epoch 27/100\n",
      "259/259 [==============================] - 0s 994us/step - loss: 0.3784 - accuracy: 0.8295\n",
      "Epoch 28/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3781 - accuracy: 0.8298\n",
      "Epoch 29/100\n",
      "259/259 [==============================] - 0s 999us/step - loss: 0.3760 - accuracy: 0.8303\n",
      "Epoch 30/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8265\n",
      "Epoch 31/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3742 - accuracy: 0.8321\n",
      "Epoch 32/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3746 - accuracy: 0.8322\n",
      "Epoch 33/100\n",
      "259/259 [==============================] - 0s 992us/step - loss: 0.3731 - accuracy: 0.8323\n",
      "Epoch 34/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3721 - accuracy: 0.8324\n",
      "Epoch 35/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3709 - accuracy: 0.8303\n",
      "Epoch 36/100\n",
      "259/259 [==============================] - 0s 982us/step - loss: 0.3713 - accuracy: 0.8303\n",
      "Epoch 37/100\n",
      "259/259 [==============================] - 0s 999us/step - loss: 0.3701 - accuracy: 0.8327\n",
      "Epoch 38/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3703 - accuracy: 0.8327\n",
      "Epoch 39/100\n",
      "259/259 [==============================] - 0s 984us/step - loss: 0.3680 - accuracy: 0.8366\n",
      "Epoch 40/100\n",
      "259/259 [==============================] - 0s 984us/step - loss: 0.3674 - accuracy: 0.8344\n",
      "Epoch 41/100\n",
      "259/259 [==============================] - 0s 992us/step - loss: 0.3691 - accuracy: 0.8340\n",
      "Epoch 42/100\n",
      "259/259 [==============================] - 0s 989us/step - loss: 0.3678 - accuracy: 0.8346\n",
      "Epoch 43/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3668 - accuracy: 0.8355\n",
      "Epoch 44/100\n",
      "259/259 [==============================] - 0s 986us/step - loss: 0.3668 - accuracy: 0.8343\n",
      "Epoch 45/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3650 - accuracy: 0.8350\n",
      "Epoch 46/100\n",
      "259/259 [==============================] - 0s 991us/step - loss: 0.3649 - accuracy: 0.8357\n",
      "Epoch 47/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3641 - accuracy: 0.8349\n",
      "Epoch 48/100\n",
      "259/259 [==============================] - 0s 982us/step - loss: 0.3642 - accuracy: 0.8370\n",
      "Epoch 49/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3625 - accuracy: 0.8369\n",
      "Epoch 50/100\n",
      "259/259 [==============================] - 0s 1000us/step - loss: 0.3629 - accuracy: 0.8377\n",
      "Epoch 51/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3639 - accuracy: 0.8369\n",
      "Epoch 52/100\n",
      "259/259 [==============================] - 0s 980us/step - loss: 0.3632 - accuracy: 0.8347\n",
      "Epoch 53/100\n",
      "259/259 [==============================] - 0s 999us/step - loss: 0.3615 - accuracy: 0.8356\n",
      "Epoch 54/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3612 - accuracy: 0.8363\n",
      "Epoch 55/100\n",
      "259/259 [==============================] - 0s 994us/step - loss: 0.3615 - accuracy: 0.8354\n",
      "Epoch 56/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3613 - accuracy: 0.8363\n",
      "Epoch 57/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3598 - accuracy: 0.8340\n",
      "Epoch 58/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3606 - accuracy: 0.8341\n",
      "Epoch 59/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.8361\n",
      "Epoch 60/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8391\n",
      "Epoch 61/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3594 - accuracy: 0.8361\n",
      "Epoch 62/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3588 - accuracy: 0.8386\n",
      "Epoch 63/100\n",
      "259/259 [==============================] - 0s 993us/step - loss: 0.3580 - accuracy: 0.8372\n",
      "Epoch 64/100\n",
      "259/259 [==============================] - 0s 994us/step - loss: 0.3583 - accuracy: 0.8380\n",
      "Epoch 65/100\n",
      "259/259 [==============================] - 0s 994us/step - loss: 0.3571 - accuracy: 0.8358\n",
      "Epoch 66/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3568 - accuracy: 0.8383\n",
      "Epoch 67/100\n",
      "259/259 [==============================] - 0s 989us/step - loss: 0.3568 - accuracy: 0.8386\n",
      "Epoch 68/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8390\n",
      "Epoch 69/100\n",
      "259/259 [==============================] - 0s 996us/step - loss: 0.3561 - accuracy: 0.8397\n",
      "Epoch 70/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3558 - accuracy: 0.8364\n",
      "Epoch 71/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8409\n",
      "Epoch 72/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8410\n",
      "Epoch 73/100\n",
      "259/259 [==============================] - 0s 994us/step - loss: 0.3553 - accuracy: 0.8373\n",
      "Epoch 74/100\n",
      "259/259 [==============================] - 0s 989us/step - loss: 0.3552 - accuracy: 0.8392\n",
      "Epoch 75/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3556 - accuracy: 0.8414\n",
      "Epoch 76/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8402\n",
      "Epoch 77/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3546 - accuracy: 0.8373\n",
      "Epoch 78/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3533 - accuracy: 0.8397\n",
      "Epoch 79/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3540 - accuracy: 0.8408\n",
      "Epoch 80/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3539 - accuracy: 0.8401\n",
      "Epoch 81/100\n",
      "259/259 [==============================] - 0s 987us/step - loss: 0.3529 - accuracy: 0.8401\n",
      "Epoch 82/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3522 - accuracy: 0.8414\n",
      "Epoch 83/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3528 - accuracy: 0.8393\n",
      "Epoch 84/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8403\n",
      "Epoch 85/100\n",
      "259/259 [==============================] - 0s 984us/step - loss: 0.3527 - accuracy: 0.8408\n",
      "Epoch 86/100\n",
      "259/259 [==============================] - 0s 997us/step - loss: 0.3516 - accuracy: 0.8406\n",
      "Epoch 87/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3523 - accuracy: 0.8389\n",
      "Epoch 88/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3514 - accuracy: 0.8403\n",
      "Epoch 89/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3537 - accuracy: 0.8401\n",
      "Epoch 90/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3515 - accuracy: 0.8407\n",
      "Epoch 91/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3510 - accuracy: 0.8402\n",
      "Epoch 92/100\n",
      "259/259 [==============================] - 0s 978us/step - loss: 0.3514 - accuracy: 0.8407\n",
      "Epoch 93/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.8420\n",
      "Epoch 94/100\n",
      "259/259 [==============================] - 0s 981us/step - loss: 0.3498 - accuracy: 0.8430\n",
      "Epoch 95/100\n",
      "259/259 [==============================] - 0s 997us/step - loss: 0.3490 - accuracy: 0.8419\n",
      "Epoch 96/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8421\n",
      "Epoch 97/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3500 - accuracy: 0.8419\n",
      "Epoch 98/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3492 - accuracy: 0.8415\n",
      "Epoch 99/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3506 - accuracy: 0.8402\n",
      "Epoch 100/100\n",
      "259/259 [==============================] - 0s 1ms/step - loss: 0.3489 - accuracy: 0.8395\n",
      "65/65 [==============================] - 0s 870us/step - loss: 0.3954 - accuracy: 0.8224\n",
      "[0.39542871713638306, 0.8223620653152466]\n",
      "65/65 [==============================] - 0s 804us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.82      0.82      1033\n",
      "         1.0       0.82      0.82      0.82      1033\n",
      "\n",
      "    accuracy                           0.82      2066\n",
      "   macro avg       0.82      0.82      0.82      2066\n",
      "weighted avg       0.82      0.82      0.82      2066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size = 0.2, stratify = y_sm)\n",
    "\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "y_pred = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c923fa35-f345-4c40-bb01-89078ec9e04d",
   "metadata": {},
   "source": [
    "Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cb703a0a-e256-4abf-9a6f-0c4422bef08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0    5163\n",
       "1    1869\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c827dd27-84e8-41ae-934c-203064eb6add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0.0    1033\n",
       "1.0     374\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 15, stratify = y)\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "711cd10e-628b-4677-93a3-d6ed23bf0d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.762541806020067"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the ratio - to determine the split size\n",
    "\n",
    "4130 / 1495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d35bb9f1-51f4-42fb-abd5-ddd9ee017293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1376.6666666666667"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4130 / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ed168841-50a0-43f6-b2d9-a9835fc53961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the classes\n",
    "df3 = X_train.copy()\n",
    "df3[\"Churn\"] = y_train\n",
    "\n",
    "df3_class_0 = df3[df3[\"Churn\"] == 0]\n",
    "df3_class_1 = df3[df3[\"Churn\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1fbfb373-bd0b-495a-911b-ca2b375f03c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4130, 27), (1495, 27))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0.shape, df_class_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "15b86035-b8c8-43e2-a205-40923a99e357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1495, 27)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_0[:1495].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "096bf0b3-07fa-42ac-b344-ae5b647cd115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis = 0)\n",
    "\n",
    "    X_train = df_train.drop(\"Churn\", axis = 1)\n",
    "    y_train = df_train[\"Churn\"]\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "399de528-7384-4f57-83b8-ab473ce63d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 934us/step - loss: 0.6344 - accuracy: 0.6522\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 878us/step - loss: 0.5215 - accuracy: 0.7572\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 878us/step - loss: 0.5020 - accuracy: 0.7602\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 898us/step - loss: 0.4939 - accuracy: 0.7635\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 856us/step - loss: 0.4898 - accuracy: 0.7672\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 853us/step - loss: 0.4858 - accuracy: 0.7639\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 888us/step - loss: 0.4826 - accuracy: 0.7666\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4813 - accuracy: 0.7642\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 886us/step - loss: 0.4800 - accuracy: 0.7702\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 902us/step - loss: 0.4787 - accuracy: 0.7686\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 896us/step - loss: 0.4782 - accuracy: 0.7689\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 867us/step - loss: 0.4765 - accuracy: 0.7669\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 864us/step - loss: 0.4744 - accuracy: 0.7702\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 828us/step - loss: 0.4750 - accuracy: 0.7729\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 864us/step - loss: 0.4728 - accuracy: 0.7736\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 876us/step - loss: 0.4735 - accuracy: 0.7739\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 889us/step - loss: 0.4713 - accuracy: 0.7716\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 846us/step - loss: 0.4705 - accuracy: 0.7759\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 880us/step - loss: 0.4703 - accuracy: 0.7712\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 881us/step - loss: 0.4707 - accuracy: 0.7753\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.4688 - accuracy: 0.7786\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 855us/step - loss: 0.4684 - accuracy: 0.7749\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 841us/step - loss: 0.4682 - accuracy: 0.7729\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 855us/step - loss: 0.4680 - accuracy: 0.7786\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 909us/step - loss: 0.4681 - accuracy: 0.7763\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 887us/step - loss: 0.4657 - accuracy: 0.7766\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 884us/step - loss: 0.4649 - accuracy: 0.7746\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 864us/step - loss: 0.4643 - accuracy: 0.7776\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 905us/step - loss: 0.4650 - accuracy: 0.7796\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 885us/step - loss: 0.4657 - accuracy: 0.7783\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 867us/step - loss: 0.4627 - accuracy: 0.7786\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 851us/step - loss: 0.4636 - accuracy: 0.7756\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 881us/step - loss: 0.4628 - accuracy: 0.7789\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7829\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 862us/step - loss: 0.4620 - accuracy: 0.7833\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 870us/step - loss: 0.4611 - accuracy: 0.7796\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 932us/step - loss: 0.4598 - accuracy: 0.7839\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 836us/step - loss: 0.4593 - accuracy: 0.7853\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 849us/step - loss: 0.4588 - accuracy: 0.7809\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 877us/step - loss: 0.4577 - accuracy: 0.7849\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 874us/step - loss: 0.4583 - accuracy: 0.7873\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 862us/step - loss: 0.4572 - accuracy: 0.7849\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 862us/step - loss: 0.4585 - accuracy: 0.7823\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 850us/step - loss: 0.4563 - accuracy: 0.7839\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 869us/step - loss: 0.4554 - accuracy: 0.7843\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 856us/step - loss: 0.4555 - accuracy: 0.7880\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 871us/step - loss: 0.4535 - accuracy: 0.7843\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 856us/step - loss: 0.4547 - accuracy: 0.7903\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 877us/step - loss: 0.4544 - accuracy: 0.7880\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 889us/step - loss: 0.4536 - accuracy: 0.7876\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 959us/step - loss: 0.4533 - accuracy: 0.7856\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.4519 - accuracy: 0.7853\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 913us/step - loss: 0.4516 - accuracy: 0.7886\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.4521 - accuracy: 0.7860\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 875us/step - loss: 0.4506 - accuracy: 0.7896\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 876us/step - loss: 0.4500 - accuracy: 0.7900\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 868us/step - loss: 0.4501 - accuracy: 0.7916\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 865us/step - loss: 0.4525 - accuracy: 0.7876\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 866us/step - loss: 0.4490 - accuracy: 0.7880\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 891us/step - loss: 0.4487 - accuracy: 0.7873\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 891us/step - loss: 0.4484 - accuracy: 0.7890\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 898us/step - loss: 0.4467 - accuracy: 0.7950\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 899us/step - loss: 0.4479 - accuracy: 0.7890\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 855us/step - loss: 0.4468 - accuracy: 0.7876\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 919us/step - loss: 0.4472 - accuracy: 0.7923\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 898us/step - loss: 0.4458 - accuracy: 0.7940\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 917us/step - loss: 0.4452 - accuracy: 0.7886\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 863us/step - loss: 0.4445 - accuracy: 0.7913\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.4443 - accuracy: 0.7916\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4441 - accuracy: 0.7913\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 994us/step - loss: 0.4450 - accuracy: 0.7880\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 879us/step - loss: 0.4442 - accuracy: 0.7890\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 908us/step - loss: 0.4427 - accuracy: 0.7936\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 905us/step - loss: 0.4433 - accuracy: 0.7930\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 906us/step - loss: 0.4428 - accuracy: 0.7920\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 884us/step - loss: 0.4417 - accuracy: 0.7890\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 911us/step - loss: 0.4419 - accuracy: 0.7943\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 918us/step - loss: 0.4415 - accuracy: 0.7950\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 916us/step - loss: 0.4403 - accuracy: 0.7936\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 876us/step - loss: 0.4405 - accuracy: 0.7980\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 883us/step - loss: 0.4408 - accuracy: 0.7963\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 891us/step - loss: 0.4409 - accuracy: 0.7933\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 886us/step - loss: 0.4395 - accuracy: 0.7950\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 884us/step - loss: 0.4396 - accuracy: 0.7953\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 865us/step - loss: 0.4389 - accuracy: 0.7910\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 879us/step - loss: 0.4382 - accuracy: 0.7953\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 905us/step - loss: 0.4397 - accuracy: 0.7916\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 960us/step - loss: 0.4386 - accuracy: 0.7946\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 892us/step - loss: 0.4382 - accuracy: 0.7943\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 897us/step - loss: 0.4379 - accuracy: 0.7977\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 899us/step - loss: 0.4373 - accuracy: 0.7923\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7990\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7997\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 921us/step - loss: 0.4386 - accuracy: 0.7910\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 856us/step - loss: 0.4358 - accuracy: 0.7973\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 867us/step - loss: 0.4354 - accuracy: 0.7963\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 896us/step - loss: 0.4347 - accuracy: 0.7970\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 923us/step - loss: 0.4355 - accuracy: 0.7973\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 881us/step - loss: 0.4352 - accuracy: 0.7933\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 887us/step - loss: 0.4346 - accuracy: 0.7997\n",
      "44/44 [==============================] - 0s 838us/step - loss: 0.5191 - accuracy: 0.7342\n",
      "[0.5191190242767334, 0.7341862320899963]\n",
      "44/44 [==============================] - 0s 685us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.73      0.80      1033\n",
      "         1.0       0.50      0.76      0.60       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.70      0.74      0.70      1407\n",
      "weighted avg       0.79      0.73      0.75      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_class_0, df_class_1, 0, 1495)\n",
    "\n",
    "X_test = X_test.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e39b16e9-9431-49f5-8b41-b919dc2478ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "94/94 [==============================] - 1s 899us/step - loss: 0.6031 - accuracy: 0.6779\n",
      "Epoch 2/100\n",
      "94/94 [==============================] - 0s 873us/step - loss: 0.5148 - accuracy: 0.7528\n",
      "Epoch 3/100\n",
      "94/94 [==============================] - 0s 897us/step - loss: 0.5016 - accuracy: 0.7565\n",
      "Epoch 4/100\n",
      "94/94 [==============================] - 0s 885us/step - loss: 0.4942 - accuracy: 0.7612\n",
      "Epoch 5/100\n",
      "94/94 [==============================] - 0s 905us/step - loss: 0.4897 - accuracy: 0.7629\n",
      "Epoch 6/100\n",
      "94/94 [==============================] - 0s 929us/step - loss: 0.4866 - accuracy: 0.7642\n",
      "Epoch 7/100\n",
      "94/94 [==============================] - 0s 863us/step - loss: 0.4839 - accuracy: 0.7649\n",
      "Epoch 8/100\n",
      "94/94 [==============================] - 0s 896us/step - loss: 0.4817 - accuracy: 0.7615\n",
      "Epoch 9/100\n",
      "94/94 [==============================] - 0s 870us/step - loss: 0.4793 - accuracy: 0.7645\n",
      "Epoch 10/100\n",
      "94/94 [==============================] - 0s 905us/step - loss: 0.4785 - accuracy: 0.7645\n",
      "Epoch 11/100\n",
      "94/94 [==============================] - 0s 902us/step - loss: 0.4761 - accuracy: 0.7635\n",
      "Epoch 12/100\n",
      "94/94 [==============================] - 0s 919us/step - loss: 0.4756 - accuracy: 0.7632\n",
      "Epoch 13/100\n",
      "94/94 [==============================] - 0s 905us/step - loss: 0.4742 - accuracy: 0.7662\n",
      "Epoch 14/100\n",
      "94/94 [==============================] - 0s 928us/step - loss: 0.4731 - accuracy: 0.7676\n",
      "Epoch 15/100\n",
      "94/94 [==============================] - 0s 875us/step - loss: 0.4714 - accuracy: 0.7656\n",
      "Epoch 16/100\n",
      "94/94 [==============================] - 0s 907us/step - loss: 0.4730 - accuracy: 0.7669\n",
      "Epoch 17/100\n",
      "94/94 [==============================] - 0s 913us/step - loss: 0.4700 - accuracy: 0.7666\n",
      "Epoch 18/100\n",
      "94/94 [==============================] - 0s 919us/step - loss: 0.4693 - accuracy: 0.7672\n",
      "Epoch 19/100\n",
      "94/94 [==============================] - 0s 884us/step - loss: 0.4672 - accuracy: 0.7676\n",
      "Epoch 20/100\n",
      "94/94 [==============================] - 0s 891us/step - loss: 0.4670 - accuracy: 0.7659\n",
      "Epoch 21/100\n",
      "94/94 [==============================] - 0s 952us/step - loss: 0.4655 - accuracy: 0.7696\n",
      "Epoch 22/100\n",
      "94/94 [==============================] - 0s 923us/step - loss: 0.4652 - accuracy: 0.7682\n",
      "Epoch 23/100\n",
      "94/94 [==============================] - 0s 918us/step - loss: 0.4636 - accuracy: 0.7696\n",
      "Epoch 24/100\n",
      "94/94 [==============================] - 0s 943us/step - loss: 0.4633 - accuracy: 0.7699\n",
      "Epoch 25/100\n",
      "94/94 [==============================] - 0s 921us/step - loss: 0.4616 - accuracy: 0.7712\n",
      "Epoch 26/100\n",
      "94/94 [==============================] - 0s 913us/step - loss: 0.4617 - accuracy: 0.7706\n",
      "Epoch 27/100\n",
      "94/94 [==============================] - 0s 869us/step - loss: 0.4605 - accuracy: 0.7726\n",
      "Epoch 28/100\n",
      "94/94 [==============================] - 0s 947us/step - loss: 0.4601 - accuracy: 0.7722\n",
      "Epoch 29/100\n",
      "94/94 [==============================] - 0s 972us/step - loss: 0.4589 - accuracy: 0.7753\n",
      "Epoch 30/100\n",
      "94/94 [==============================] - 0s 953us/step - loss: 0.4586 - accuracy: 0.7729\n",
      "Epoch 31/100\n",
      "94/94 [==============================] - 0s 896us/step - loss: 0.4575 - accuracy: 0.7759\n",
      "Epoch 32/100\n",
      "94/94 [==============================] - 0s 877us/step - loss: 0.4563 - accuracy: 0.7746\n",
      "Epoch 33/100\n",
      "94/94 [==============================] - 0s 854us/step - loss: 0.4561 - accuracy: 0.7769\n",
      "Epoch 34/100\n",
      "94/94 [==============================] - 0s 926us/step - loss: 0.4552 - accuracy: 0.7786\n",
      "Epoch 35/100\n",
      "94/94 [==============================] - 0s 920us/step - loss: 0.4551 - accuracy: 0.7702\n",
      "Epoch 36/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7783\n",
      "Epoch 37/100\n",
      "94/94 [==============================] - 0s 933us/step - loss: 0.4531 - accuracy: 0.7753\n",
      "Epoch 38/100\n",
      "94/94 [==============================] - 0s 893us/step - loss: 0.4531 - accuracy: 0.7786\n",
      "Epoch 39/100\n",
      "94/94 [==============================] - 0s 887us/step - loss: 0.4519 - accuracy: 0.7786\n",
      "Epoch 40/100\n",
      "94/94 [==============================] - 0s 934us/step - loss: 0.4512 - accuracy: 0.7779\n",
      "Epoch 41/100\n",
      "94/94 [==============================] - 0s 914us/step - loss: 0.4498 - accuracy: 0.7809\n",
      "Epoch 42/100\n",
      "94/94 [==============================] - 0s 900us/step - loss: 0.4502 - accuracy: 0.7753\n",
      "Epoch 43/100\n",
      "94/94 [==============================] - 0s 929us/step - loss: 0.4492 - accuracy: 0.7803\n",
      "Epoch 44/100\n",
      "94/94 [==============================] - 0s 871us/step - loss: 0.4481 - accuracy: 0.7813\n",
      "Epoch 45/100\n",
      "94/94 [==============================] - 0s 893us/step - loss: 0.4486 - accuracy: 0.7793\n",
      "Epoch 46/100\n",
      "94/94 [==============================] - 0s 906us/step - loss: 0.4464 - accuracy: 0.7799\n",
      "Epoch 47/100\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.4472 - accuracy: 0.7826\n",
      "Epoch 48/100\n",
      "94/94 [==============================] - 0s 906us/step - loss: 0.4462 - accuracy: 0.7843\n",
      "Epoch 49/100\n",
      "94/94 [==============================] - 0s 908us/step - loss: 0.4463 - accuracy: 0.7826\n",
      "Epoch 50/100\n",
      "94/94 [==============================] - 0s 911us/step - loss: 0.4447 - accuracy: 0.7853\n",
      "Epoch 51/100\n",
      "94/94 [==============================] - 0s 959us/step - loss: 0.4455 - accuracy: 0.7846\n",
      "Epoch 52/100\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.4439 - accuracy: 0.7846\n",
      "Epoch 53/100\n",
      "94/94 [==============================] - 0s 899us/step - loss: 0.4430 - accuracy: 0.7856\n",
      "Epoch 54/100\n",
      "94/94 [==============================] - 0s 940us/step - loss: 0.4428 - accuracy: 0.7876\n",
      "Epoch 55/100\n",
      "94/94 [==============================] - 0s 908us/step - loss: 0.4419 - accuracy: 0.7876\n",
      "Epoch 56/100\n",
      "94/94 [==============================] - 0s 867us/step - loss: 0.4413 - accuracy: 0.7843\n",
      "Epoch 57/100\n",
      "94/94 [==============================] - 0s 874us/step - loss: 0.4400 - accuracy: 0.7843\n",
      "Epoch 58/100\n",
      "94/94 [==============================] - 0s 863us/step - loss: 0.4411 - accuracy: 0.7886\n",
      "Epoch 59/100\n",
      "94/94 [==============================] - 0s 919us/step - loss: 0.4411 - accuracy: 0.7876\n",
      "Epoch 60/100\n",
      "94/94 [==============================] - 0s 910us/step - loss: 0.4394 - accuracy: 0.7906\n",
      "Epoch 61/100\n",
      "94/94 [==============================] - 0s 901us/step - loss: 0.4384 - accuracy: 0.7856\n",
      "Epoch 62/100\n",
      "94/94 [==============================] - 0s 911us/step - loss: 0.4384 - accuracy: 0.7866\n",
      "Epoch 63/100\n",
      "94/94 [==============================] - 0s 908us/step - loss: 0.4378 - accuracy: 0.7913\n",
      "Epoch 64/100\n",
      "94/94 [==============================] - 0s 860us/step - loss: 0.4365 - accuracy: 0.7906\n",
      "Epoch 65/100\n",
      "94/94 [==============================] - 0s 872us/step - loss: 0.4361 - accuracy: 0.7903\n",
      "Epoch 66/100\n",
      "94/94 [==============================] - 0s 877us/step - loss: 0.4360 - accuracy: 0.7893\n",
      "Epoch 67/100\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.4346 - accuracy: 0.7920\n",
      "Epoch 68/100\n",
      "94/94 [==============================] - 0s 920us/step - loss: 0.4342 - accuracy: 0.7900\n",
      "Epoch 69/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4348 - accuracy: 0.7953\n",
      "Epoch 70/100\n",
      "94/94 [==============================] - 0s 889us/step - loss: 0.4346 - accuracy: 0.7910\n",
      "Epoch 71/100\n",
      "94/94 [==============================] - 0s 906us/step - loss: 0.4330 - accuracy: 0.7950\n",
      "Epoch 72/100\n",
      "94/94 [==============================] - 0s 900us/step - loss: 0.4331 - accuracy: 0.7930\n",
      "Epoch 73/100\n",
      "94/94 [==============================] - 0s 909us/step - loss: 0.4328 - accuracy: 0.7957\n",
      "Epoch 74/100\n",
      "94/94 [==============================] - 0s 936us/step - loss: 0.4318 - accuracy: 0.7913\n",
      "Epoch 75/100\n",
      "94/94 [==============================] - 0s 920us/step - loss: 0.4316 - accuracy: 0.7933\n",
      "Epoch 76/100\n",
      "94/94 [==============================] - 0s 893us/step - loss: 0.4306 - accuracy: 0.7936\n",
      "Epoch 77/100\n",
      "94/94 [==============================] - 0s 926us/step - loss: 0.4307 - accuracy: 0.7953\n",
      "Epoch 78/100\n",
      "94/94 [==============================] - 0s 919us/step - loss: 0.4310 - accuracy: 0.7957\n",
      "Epoch 79/100\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.4292 - accuracy: 0.7950\n",
      "Epoch 80/100\n",
      "94/94 [==============================] - 0s 859us/step - loss: 0.4289 - accuracy: 0.7963\n",
      "Epoch 81/100\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.4286 - accuracy: 0.7960\n",
      "Epoch 82/100\n",
      "94/94 [==============================] - 0s 933us/step - loss: 0.4274 - accuracy: 0.7993\n",
      "Epoch 83/100\n",
      "94/94 [==============================] - 0s 935us/step - loss: 0.4288 - accuracy: 0.7993\n",
      "Epoch 84/100\n",
      "94/94 [==============================] - 0s 871us/step - loss: 0.4275 - accuracy: 0.8027\n",
      "Epoch 85/100\n",
      "94/94 [==============================] - 0s 889us/step - loss: 0.4272 - accuracy: 0.8000\n",
      "Epoch 86/100\n",
      "94/94 [==============================] - 0s 913us/step - loss: 0.4272 - accuracy: 0.7993\n",
      "Epoch 87/100\n",
      "94/94 [==============================] - 0s 917us/step - loss: 0.4272 - accuracy: 0.7936\n",
      "Epoch 88/100\n",
      "94/94 [==============================] - 0s 923us/step - loss: 0.4263 - accuracy: 0.7993\n",
      "Epoch 89/100\n",
      "94/94 [==============================] - 0s 912us/step - loss: 0.4258 - accuracy: 0.8027\n",
      "Epoch 90/100\n",
      "94/94 [==============================] - 0s 876us/step - loss: 0.4258 - accuracy: 0.7980\n",
      "Epoch 91/100\n",
      "94/94 [==============================] - 0s 886us/step - loss: 0.4243 - accuracy: 0.8003\n",
      "Epoch 92/100\n",
      "94/94 [==============================] - 0s 865us/step - loss: 0.4249 - accuracy: 0.8013\n",
      "Epoch 93/100\n",
      "94/94 [==============================] - 0s 899us/step - loss: 0.4232 - accuracy: 0.8030\n",
      "Epoch 94/100\n",
      "94/94 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8030\n",
      "Epoch 95/100\n",
      "94/94 [==============================] - 0s 916us/step - loss: 0.4228 - accuracy: 0.8033\n",
      "Epoch 96/100\n",
      "94/94 [==============================] - 0s 939us/step - loss: 0.4234 - accuracy: 0.8023\n",
      "Epoch 97/100\n",
      "94/94 [==============================] - 0s 913us/step - loss: 0.4220 - accuracy: 0.7997\n",
      "Epoch 98/100\n",
      "94/94 [==============================] - 0s 890us/step - loss: 0.4226 - accuracy: 0.8007\n",
      "Epoch 99/100\n",
      "94/94 [==============================] - 0s 925us/step - loss: 0.4218 - accuracy: 0.8027\n",
      "Epoch 100/100\n",
      "94/94 [==============================] - 0s 879us/step - loss: 0.4223 - accuracy: 0.8020\n",
      "44/44 [==============================] - 0s 806us/step - loss: 0.5326 - accuracy: 0.7235\n",
      "[0.5326429009437561, 0.7235252261161804]\n",
      "44/44 [==============================] - 0s 691us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.72      0.79      1033\n",
      "         1.0       0.49      0.74      0.59       374\n",
      "\n",
      "    accuracy                           0.72      1407\n",
      "   macro avg       0.69      0.73      0.69      1407\n",
      "weighted avg       0.78      0.72      0.74      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_class_0, df_class_1, 1495, 2990)\n",
    "\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0c7e1c36-f457-40e4-96ca-a9061cc9dd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "83/83 [==============================] - 1s 885us/step - loss: 0.5973 - accuracy: 0.7006\n",
      "Epoch 2/100\n",
      "83/83 [==============================] - 0s 903us/step - loss: 0.5161 - accuracy: 0.7476\n",
      "Epoch 3/100\n",
      "83/83 [==============================] - 0s 877us/step - loss: 0.4995 - accuracy: 0.7583\n",
      "Epoch 4/100\n",
      "83/83 [==============================] - 0s 870us/step - loss: 0.4912 - accuracy: 0.7594\n",
      "Epoch 5/100\n",
      "83/83 [==============================] - 0s 847us/step - loss: 0.4867 - accuracy: 0.7624\n",
      "Epoch 6/100\n",
      "83/83 [==============================] - 0s 874us/step - loss: 0.4835 - accuracy: 0.7628\n",
      "Epoch 7/100\n",
      "83/83 [==============================] - 0s 888us/step - loss: 0.4792 - accuracy: 0.7734\n",
      "Epoch 8/100\n",
      "83/83 [==============================] - 0s 846us/step - loss: 0.4775 - accuracy: 0.7681\n",
      "Epoch 9/100\n",
      "83/83 [==============================] - 0s 873us/step - loss: 0.4753 - accuracy: 0.7723\n",
      "Epoch 10/100\n",
      "83/83 [==============================] - 0s 840us/step - loss: 0.4739 - accuracy: 0.7750\n",
      "Epoch 11/100\n",
      "83/83 [==============================] - 0s 893us/step - loss: 0.4718 - accuracy: 0.7742\n",
      "Epoch 12/100\n",
      "83/83 [==============================] - 0s 881us/step - loss: 0.4704 - accuracy: 0.7780\n",
      "Epoch 13/100\n",
      "83/83 [==============================] - 0s 883us/step - loss: 0.4688 - accuracy: 0.7765\n",
      "Epoch 14/100\n",
      "83/83 [==============================] - 0s 889us/step - loss: 0.4667 - accuracy: 0.7780\n",
      "Epoch 15/100\n",
      "83/83 [==============================] - 0s 863us/step - loss: 0.4646 - accuracy: 0.7772\n",
      "Epoch 16/100\n",
      "83/83 [==============================] - 0s 900us/step - loss: 0.4629 - accuracy: 0.7837\n",
      "Epoch 17/100\n",
      "83/83 [==============================] - 0s 891us/step - loss: 0.4629 - accuracy: 0.7837\n",
      "Epoch 18/100\n",
      "83/83 [==============================] - 0s 889us/step - loss: 0.4613 - accuracy: 0.7814\n",
      "Epoch 19/100\n",
      "83/83 [==============================] - 0s 887us/step - loss: 0.4591 - accuracy: 0.7848\n",
      "Epoch 20/100\n",
      "83/83 [==============================] - 0s 855us/step - loss: 0.4580 - accuracy: 0.7871\n",
      "Epoch 21/100\n",
      "83/83 [==============================] - 0s 886us/step - loss: 0.4559 - accuracy: 0.7882\n",
      "Epoch 22/100\n",
      "83/83 [==============================] - 0s 842us/step - loss: 0.4561 - accuracy: 0.7829\n",
      "Epoch 23/100\n",
      "83/83 [==============================] - 0s 904us/step - loss: 0.4548 - accuracy: 0.7886\n",
      "Epoch 24/100\n",
      "83/83 [==============================] - 0s 880us/step - loss: 0.4515 - accuracy: 0.7909\n",
      "Epoch 25/100\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7894\n",
      "Epoch 26/100\n",
      "83/83 [==============================] - 0s 880us/step - loss: 0.4491 - accuracy: 0.7894\n",
      "Epoch 27/100\n",
      "83/83 [==============================] - 0s 875us/step - loss: 0.4480 - accuracy: 0.7920\n",
      "Epoch 28/100\n",
      "83/83 [==============================] - 0s 867us/step - loss: 0.4464 - accuracy: 0.7924\n",
      "Epoch 29/100\n",
      "83/83 [==============================] - 0s 877us/step - loss: 0.4470 - accuracy: 0.7898\n",
      "Epoch 30/100\n",
      "83/83 [==============================] - 0s 900us/step - loss: 0.4448 - accuracy: 0.7924\n",
      "Epoch 31/100\n",
      "83/83 [==============================] - 0s 852us/step - loss: 0.4429 - accuracy: 0.7962\n",
      "Epoch 32/100\n",
      "83/83 [==============================] - 0s 884us/step - loss: 0.4431 - accuracy: 0.7966\n",
      "Epoch 33/100\n",
      "83/83 [==============================] - 0s 884us/step - loss: 0.4421 - accuracy: 0.7970\n",
      "Epoch 34/100\n",
      "83/83 [==============================] - 0s 888us/step - loss: 0.4400 - accuracy: 0.7970\n",
      "Epoch 35/100\n",
      "83/83 [==============================] - 0s 842us/step - loss: 0.4394 - accuracy: 0.7966\n",
      "Epoch 36/100\n",
      "83/83 [==============================] - 0s 899us/step - loss: 0.4384 - accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "83/83 [==============================] - 0s 870us/step - loss: 0.4375 - accuracy: 0.7996\n",
      "Epoch 38/100\n",
      "83/83 [==============================] - 0s 879us/step - loss: 0.4387 - accuracy: 0.7992\n",
      "Epoch 39/100\n",
      "83/83 [==============================] - 0s 879us/step - loss: 0.4365 - accuracy: 0.7977\n",
      "Epoch 40/100\n",
      "83/83 [==============================] - 0s 885us/step - loss: 0.4352 - accuracy: 0.8011\n",
      "Epoch 41/100\n",
      "83/83 [==============================] - 0s 849us/step - loss: 0.4348 - accuracy: 0.7973\n",
      "Epoch 42/100\n",
      "83/83 [==============================] - 0s 939us/step - loss: 0.4338 - accuracy: 0.8023\n",
      "Epoch 43/100\n",
      "83/83 [==============================] - 0s 866us/step - loss: 0.4325 - accuracy: 0.7992\n",
      "Epoch 44/100\n",
      "83/83 [==============================] - 0s 873us/step - loss: 0.4314 - accuracy: 0.8034\n",
      "Epoch 45/100\n",
      "83/83 [==============================] - 0s 842us/step - loss: 0.4304 - accuracy: 0.8011\n",
      "Epoch 46/100\n",
      "83/83 [==============================] - 0s 877us/step - loss: 0.4305 - accuracy: 0.7989\n",
      "Epoch 47/100\n",
      "83/83 [==============================] - 0s 902us/step - loss: 0.4285 - accuracy: 0.8027\n",
      "Epoch 48/100\n",
      "83/83 [==============================] - 0s 901us/step - loss: 0.4283 - accuracy: 0.8042\n",
      "Epoch 49/100\n",
      "83/83 [==============================] - 0s 869us/step - loss: 0.4285 - accuracy: 0.8019\n",
      "Epoch 50/100\n",
      "83/83 [==============================] - 0s 868us/step - loss: 0.4264 - accuracy: 0.8053\n",
      "Epoch 51/100\n",
      "83/83 [==============================] - 0s 882us/step - loss: 0.4270 - accuracy: 0.8083\n",
      "Epoch 52/100\n",
      "83/83 [==============================] - 0s 992us/step - loss: 0.4271 - accuracy: 0.8030\n",
      "Epoch 53/100\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.4248 - accuracy: 0.8034\n",
      "Epoch 54/100\n",
      "83/83 [==============================] - 0s 917us/step - loss: 0.4247 - accuracy: 0.8072\n",
      "Epoch 55/100\n",
      "83/83 [==============================] - 0s 867us/step - loss: 0.4240 - accuracy: 0.8038\n",
      "Epoch 56/100\n",
      "83/83 [==============================] - 0s 879us/step - loss: 0.4231 - accuracy: 0.8019\n",
      "Epoch 57/100\n",
      "83/83 [==============================] - 0s 847us/step - loss: 0.4225 - accuracy: 0.8046\n",
      "Epoch 58/100\n",
      "83/83 [==============================] - 0s 885us/step - loss: 0.4215 - accuracy: 0.8065\n",
      "Epoch 59/100\n",
      "83/83 [==============================] - 0s 855us/step - loss: 0.4220 - accuracy: 0.8019\n",
      "Epoch 60/100\n",
      "83/83 [==============================] - 0s 875us/step - loss: 0.4214 - accuracy: 0.8038\n",
      "Epoch 61/100\n",
      "83/83 [==============================] - 0s 940us/step - loss: 0.4198 - accuracy: 0.8038\n",
      "Epoch 62/100\n",
      "83/83 [==============================] - 0s 961us/step - loss: 0.4199 - accuracy: 0.8080\n",
      "Epoch 63/100\n",
      "83/83 [==============================] - 0s 959us/step - loss: 0.4191 - accuracy: 0.8015\n",
      "Epoch 64/100\n",
      "83/83 [==============================] - 0s 844us/step - loss: 0.4186 - accuracy: 0.8042\n",
      "Epoch 65/100\n",
      "83/83 [==============================] - 0s 936us/step - loss: 0.4183 - accuracy: 0.8068\n",
      "Epoch 66/100\n",
      "83/83 [==============================] - 0s 892us/step - loss: 0.4184 - accuracy: 0.8061\n",
      "Epoch 67/100\n",
      "83/83 [==============================] - 0s 868us/step - loss: 0.4165 - accuracy: 0.8076\n",
      "Epoch 68/100\n",
      "83/83 [==============================] - 0s 853us/step - loss: 0.4156 - accuracy: 0.8099\n",
      "Epoch 69/100\n",
      "83/83 [==============================] - 0s 861us/step - loss: 0.4175 - accuracy: 0.8106\n",
      "Epoch 70/100\n",
      "83/83 [==============================] - 0s 892us/step - loss: 0.4161 - accuracy: 0.8095\n",
      "Epoch 71/100\n",
      "83/83 [==============================] - 0s 941us/step - loss: 0.4149 - accuracy: 0.8068\n",
      "Epoch 72/100\n",
      "83/83 [==============================] - 0s 936us/step - loss: 0.4149 - accuracy: 0.8057\n",
      "Epoch 73/100\n",
      "83/83 [==============================] - 0s 942us/step - loss: 0.4149 - accuracy: 0.8076\n",
      "Epoch 74/100\n",
      "83/83 [==============================] - 0s 888us/step - loss: 0.4139 - accuracy: 0.8114\n",
      "Epoch 75/100\n",
      "83/83 [==============================] - 0s 867us/step - loss: 0.4133 - accuracy: 0.8061\n",
      "Epoch 76/100\n",
      "83/83 [==============================] - 0s 940us/step - loss: 0.4143 - accuracy: 0.8114\n",
      "Epoch 77/100\n",
      "83/83 [==============================] - 0s 921us/step - loss: 0.4128 - accuracy: 0.8076\n",
      "Epoch 78/100\n",
      "83/83 [==============================] - 0s 901us/step - loss: 0.4120 - accuracy: 0.8087\n",
      "Epoch 79/100\n",
      "83/83 [==============================] - 0s 847us/step - loss: 0.4118 - accuracy: 0.8083\n",
      "Epoch 80/100\n",
      "83/83 [==============================] - 0s 819us/step - loss: 0.4112 - accuracy: 0.8083\n",
      "Epoch 81/100\n",
      "83/83 [==============================] - 0s 833us/step - loss: 0.4121 - accuracy: 0.8099\n",
      "Epoch 82/100\n",
      "83/83 [==============================] - 0s 1ms/step - loss: 0.4107 - accuracy: 0.8095\n",
      "Epoch 83/100\n",
      "83/83 [==============================] - 0s 836us/step - loss: 0.4101 - accuracy: 0.8125\n",
      "Epoch 84/100\n",
      "83/83 [==============================] - 0s 849us/step - loss: 0.4105 - accuracy: 0.8114\n",
      "Epoch 85/100\n",
      "83/83 [==============================] - 0s 905us/step - loss: 0.4091 - accuracy: 0.8095\n",
      "Epoch 86/100\n",
      "83/83 [==============================] - 0s 889us/step - loss: 0.4093 - accuracy: 0.8095\n",
      "Epoch 87/100\n",
      "83/83 [==============================] - 0s 856us/step - loss: 0.4078 - accuracy: 0.8072\n",
      "Epoch 88/100\n",
      "83/83 [==============================] - 0s 864us/step - loss: 0.4091 - accuracy: 0.8102\n",
      "Epoch 89/100\n",
      "83/83 [==============================] - 0s 827us/step - loss: 0.4075 - accuracy: 0.8091\n",
      "Epoch 90/100\n",
      "83/83 [==============================] - 0s 838us/step - loss: 0.4077 - accuracy: 0.8080\n",
      "Epoch 91/100\n",
      "83/83 [==============================] - 0s 823us/step - loss: 0.4073 - accuracy: 0.8091\n",
      "Epoch 92/100\n",
      "83/83 [==============================] - 0s 821us/step - loss: 0.4072 - accuracy: 0.8080\n",
      "Epoch 93/100\n",
      "83/83 [==============================] - 0s 832us/step - loss: 0.4067 - accuracy: 0.8133\n",
      "Epoch 94/100\n",
      "83/83 [==============================] - 0s 824us/step - loss: 0.4057 - accuracy: 0.8110\n",
      "Epoch 95/100\n",
      "83/83 [==============================] - 0s 903us/step - loss: 0.4061 - accuracy: 0.8129\n",
      "Epoch 96/100\n",
      "83/83 [==============================] - 0s 912us/step - loss: 0.4051 - accuracy: 0.8144\n",
      "Epoch 97/100\n",
      "83/83 [==============================] - 0s 886us/step - loss: 0.4049 - accuracy: 0.8106\n",
      "Epoch 98/100\n",
      "83/83 [==============================] - 0s 835us/step - loss: 0.4052 - accuracy: 0.8118\n",
      "Epoch 99/100\n",
      "83/83 [==============================] - 0s 838us/step - loss: 0.4028 - accuracy: 0.8125\n",
      "Epoch 100/100\n",
      "83/83 [==============================] - 0s 840us/step - loss: 0.4036 - accuracy: 0.8140\n",
      "44/44 [==============================] - 0s 783us/step - loss: 0.5918 - accuracy: 0.6880\n",
      "[0.5917922258377075, 0.6879886388778687]\n",
      "44/44 [==============================] - 0s 697us/step\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.64      0.75      1033\n",
      "         1.0       0.45      0.81      0.58       374\n",
      "\n",
      "    accuracy                           0.69      1407\n",
      "   macro avg       0.68      0.73      0.67      1407\n",
      "weighted avg       0.78      0.69      0.71      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df_class_0, df_class_1, 2990, 4130)\n",
    "\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, \"binary_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "864cb45e-88d8-4834-ad05-f30bde18fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the majority vote\n",
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if n_ones > 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8cf36720-801e-4760-886b-721a6139948f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.71      0.79      1033\n",
      "         1.0       0.49      0.78      0.60       374\n",
      "\n",
      "    accuracy                           0.73      1407\n",
      "   macro avg       0.70      0.74      0.70      1407\n",
      "weighted avg       0.79      0.73      0.74      1407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
